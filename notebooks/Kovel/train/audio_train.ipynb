{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# ds = load_dataset(\"luli0034/music-tags-to-spectrogram\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 512\n",
    "MY_PWD = \"/Users/akovel/Documents/HSE/Music-Predictor/\"\n",
    "DS_PATH = f\"{MY_PWD}data/spectograms\"\n",
    "MIN_NUM_GENRES = 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_size = int(len(ds))\n",
    "# subset = ds.select(range(subset_size))\n",
    "# print(subset)\n",
    "# ds = subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset_from_json(path):\n",
    "    path += \"/spectogramsgenres.json\"\n",
    "    df = pd.read_json(path)\n",
    "\n",
    "    return df.T\n",
    "\n",
    "df = read_dataset_from_json(DS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_simple_genres(df):\n",
    "    genre_counts = df['genres'].str.split(expand=True).stack().value_counts()\n",
    "    rare_genres = genre_counts[genre_counts < MIN_NUM_GENRES].index\n",
    "\n",
    "    def transform_genres_to_simple(genres_text):\n",
    "        genres = genres_text.split()\n",
    "        return ' '.join([genre for genre in genres if genre not in rare_genres])\n",
    "    df['simple_genre'] = df['genres'].apply(transform_genres_to_simple)\n",
    "    df = df[df['simple_genre'] != \"\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = make_simple_genres(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1001 entries, 0 to 1538\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   genres        1001 non-null   object\n",
      " 1   image_path    1001 non-null   object\n",
      " 2   simple_genre  1001 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 31.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>image_path</th>\n",
       "      <th>simple_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundtrack classical</td>\n",
       "      <td>/Users/akovel/Documents/HSE/Music-Predictor/da...</td>\n",
       "      <td>soundtrack classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiphop electronic latin</td>\n",
       "      <td>/Users/akovel/Documents/HSE/Music-Predictor/da...</td>\n",
       "      <td>electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soundtrack ambient classical</td>\n",
       "      <td>/Users/akovel/Documents/HSE/Music-Predictor/da...</td>\n",
       "      <td>soundtrack ambient classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soundtrack ambient classical</td>\n",
       "      <td>/Users/akovel/Documents/HSE/Music-Predictor/da...</td>\n",
       "      <td>soundtrack ambient classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>soundtrack ambient classical</td>\n",
       "      <td>/Users/akovel/Documents/HSE/Music-Predictor/da...</td>\n",
       "      <td>soundtrack ambient classical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         genres  \\\n",
       "0          soundtrack classical   \n",
       "1       hiphop electronic latin   \n",
       "3  soundtrack ambient classical   \n",
       "4  soundtrack ambient classical   \n",
       "5  soundtrack ambient classical   \n",
       "\n",
       "                                          image_path  \\\n",
       "0  /Users/akovel/Documents/HSE/Music-Predictor/da...   \n",
       "1  /Users/akovel/Documents/HSE/Music-Predictor/da...   \n",
       "3  /Users/akovel/Documents/HSE/Music-Predictor/da...   \n",
       "4  /Users/akovel/Documents/HSE/Music-Predictor/da...   \n",
       "5  /Users/akovel/Documents/HSE/Music-Predictor/da...   \n",
       "\n",
       "                   simple_genre  \n",
       "0          soundtrack classical  \n",
       "1                    electronic  \n",
       "3  soundtrack ambient classical  \n",
       "4  soundtrack ambient classical  \n",
       "5  soundtrack ambient classical  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicDataset(Dataset):\n",
    "    def __init__(self, ds, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data_frame = ds\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        genres = self.data_frame[\"simple_genre\"].iloc[index]\n",
    "        if self.transform:\n",
    "            image = Image.open(self.data_frame[\"image_path\"].iloc[index])\n",
    "            image = self.transform(image)\n",
    "        return image, genres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_collate(batch):\n",
    "#     batch = list(filter(lambda x: x is not None, batch))\n",
    "#     return default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_features(dataloader, model):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in tqdm(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            features.append(output.cpu().numpy())\n",
    "    return np.vstack(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поэтому я превращу их в квадрат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MusicDataset(ds_train, transform=image_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MusicDataset(ds_test, transform=image_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akovel/anaconda3/envs/diploma/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/akovel/anaconda3/envs/diploma/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Identity()\n",
    "model.to(device) \n",
    "resnet = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['soundtrack', 'classical']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[\"simple_genre\"][0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = [genre.split() for genre in ds_train[\"simple_genre\"]]\n",
    "all_genres_test = [genre.split()  for genre in ds_test[\"simple_genre\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ambient', 'electronic', 'newage']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_genres[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rock']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_genres_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(all_genres)\n",
    "y_test_encoder = mlb.transform(all_genres_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ambient', 'bass', 'chillout', 'classical', 'dance', 'drums',\n",
       "       'easylistening', 'electricguitar', 'electronic', 'emotional',\n",
       "       'film', 'guitar', 'happy', 'newage', 'orchestral', 'piano', 'pop',\n",
       "       'relaxing', 'rock', 'soundtrack', 'synthesizer'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [09:12<00:00, 42.50s/it]\n"
     ]
    }
   ],
   "source": [
    "train_features = extract_image_features(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_tensor = torch.tensor(train_features, dtype=torch.float32).to(device)\n",
    "labels_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegressionModel(input_size=feature_tensor.shape[1], num_classes=labels_tensor.shape[1]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline CV Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 /100], Loss: 0.7078\n",
      "Epoch [2 /100], Loss: 0.6829\n",
      "Epoch [3 /100], Loss: 0.6597\n",
      "Epoch [4 /100], Loss: 0.6380\n",
      "Epoch [5 /100], Loss: 0.6177\n",
      "Epoch [6 /100], Loss: 0.5988\n",
      "Epoch [7 /100], Loss: 0.5811\n",
      "Epoch [8 /100], Loss: 0.5645\n",
      "Epoch [9 /100], Loss: 0.5490\n",
      "Epoch [10 /100], Loss: 0.5345\n",
      "Epoch [11 /100], Loss: 0.5210\n",
      "Epoch [12 /100], Loss: 0.5083\n",
      "Epoch [13 /100], Loss: 0.4963\n",
      "Epoch [14 /100], Loss: 0.4852\n",
      "Epoch [15 /100], Loss: 0.4747\n",
      "Epoch [16 /100], Loss: 0.4648\n",
      "Epoch [17 /100], Loss: 0.4555\n",
      "Epoch [18 /100], Loss: 0.4468\n",
      "Epoch [19 /100], Loss: 0.4386\n",
      "Epoch [20 /100], Loss: 0.4308\n",
      "Epoch [21 /100], Loss: 0.4235\n",
      "Epoch [22 /100], Loss: 0.4166\n",
      "Epoch [23 /100], Loss: 0.4101\n",
      "Epoch [24 /100], Loss: 0.4039\n",
      "Epoch [25 /100], Loss: 0.3981\n",
      "Epoch [26 /100], Loss: 0.3926\n",
      "Epoch [27 /100], Loss: 0.3873\n",
      "Epoch [28 /100], Loss: 0.3824\n",
      "Epoch [29 /100], Loss: 0.3777\n",
      "Epoch [30 /100], Loss: 0.3732\n",
      "Epoch [31 /100], Loss: 0.3690\n",
      "Epoch [32 /100], Loss: 0.3650\n",
      "Epoch [33 /100], Loss: 0.3611\n",
      "Epoch [34 /100], Loss: 0.3575\n",
      "Epoch [35 /100], Loss: 0.3540\n",
      "Epoch [36 /100], Loss: 0.3507\n",
      "Epoch [37 /100], Loss: 0.3476\n",
      "Epoch [38 /100], Loss: 0.3445\n",
      "Epoch [39 /100], Loss: 0.3417\n",
      "Epoch [40 /100], Loss: 0.3389\n",
      "Epoch [41 /100], Loss: 0.3363\n",
      "Epoch [42 /100], Loss: 0.3338\n",
      "Epoch [43 /100], Loss: 0.3314\n",
      "Epoch [44 /100], Loss: 0.3291\n",
      "Epoch [45 /100], Loss: 0.3269\n",
      "Epoch [46 /100], Loss: 0.3248\n",
      "Epoch [47 /100], Loss: 0.3228\n",
      "Epoch [48 /100], Loss: 0.3208\n",
      "Epoch [49 /100], Loss: 0.3190\n",
      "Epoch [50 /100], Loss: 0.3172\n",
      "Epoch [51 /100], Loss: 0.3155\n",
      "Epoch [52 /100], Loss: 0.3139\n",
      "Epoch [53 /100], Loss: 0.3123\n",
      "Epoch [54 /100], Loss: 0.3108\n",
      "Epoch [55 /100], Loss: 0.3093\n",
      "Epoch [56 /100], Loss: 0.3079\n",
      "Epoch [57 /100], Loss: 0.3065\n",
      "Epoch [58 /100], Loss: 0.3052\n",
      "Epoch [59 /100], Loss: 0.3040\n",
      "Epoch [60 /100], Loss: 0.3028\n",
      "Epoch [61 /100], Loss: 0.3016\n",
      "Epoch [62 /100], Loss: 0.3005\n",
      "Epoch [63 /100], Loss: 0.2994\n",
      "Epoch [64 /100], Loss: 0.2984\n",
      "Epoch [65 /100], Loss: 0.2974\n",
      "Epoch [66 /100], Loss: 0.2964\n",
      "Epoch [67 /100], Loss: 0.2954\n",
      "Epoch [68 /100], Loss: 0.2945\n",
      "Epoch [69 /100], Loss: 0.2937\n",
      "Epoch [70 /100], Loss: 0.2928\n",
      "Epoch [71 /100], Loss: 0.2920\n",
      "Epoch [72 /100], Loss: 0.2912\n",
      "Epoch [73 /100], Loss: 0.2904\n",
      "Epoch [74 /100], Loss: 0.2897\n",
      "Epoch [75 /100], Loss: 0.2890\n",
      "Epoch [76 /100], Loss: 0.2883\n",
      "Epoch [77 /100], Loss: 0.2876\n",
      "Epoch [78 /100], Loss: 0.2870\n",
      "Epoch [79 /100], Loss: 0.2863\n",
      "Epoch [80 /100], Loss: 0.2857\n",
      "Epoch [81 /100], Loss: 0.2851\n",
      "Epoch [82 /100], Loss: 0.2846\n",
      "Epoch [83 /100], Loss: 0.2840\n",
      "Epoch [84 /100], Loss: 0.2835\n",
      "Epoch [85 /100], Loss: 0.2829\n",
      "Epoch [86 /100], Loss: 0.2824\n",
      "Epoch [87 /100], Loss: 0.2819\n",
      "Epoch [88 /100], Loss: 0.2814\n",
      "Epoch [89 /100], Loss: 0.2810\n",
      "Epoch [90 /100], Loss: 0.2805\n",
      "Epoch [91 /100], Loss: 0.2801\n",
      "Epoch [92 /100], Loss: 0.2797\n",
      "Epoch [93 /100], Loss: 0.2793\n",
      "Epoch [94 /100], Loss: 0.2788\n",
      "Epoch [95 /100], Loss: 0.2785\n",
      "Epoch [96 /100], Loss: 0.2781\n",
      "Epoch [97 /100], Loss: 0.2777\n",
      "Epoch [98 /100], Loss: 0.2773\n",
      "Epoch [99 /100], Loss: 0.2770\n",
      "Epoch [100 /100], Loss: 0.2767\n",
      "Epoch [101 /100], Loss: 0.2763\n",
      "Epoch [102 /100], Loss: 0.2760\n",
      "Epoch [103 /100], Loss: 0.2757\n",
      "Epoch [104 /100], Loss: 0.2754\n",
      "Epoch [105 /100], Loss: 0.2751\n",
      "Epoch [106 /100], Loss: 0.2748\n",
      "Epoch [107 /100], Loss: 0.2745\n",
      "Epoch [108 /100], Loss: 0.2742\n",
      "Epoch [109 /100], Loss: 0.2740\n",
      "Epoch [110 /100], Loss: 0.2737\n",
      "Epoch [111 /100], Loss: 0.2735\n",
      "Epoch [112 /100], Loss: 0.2732\n",
      "Epoch [113 /100], Loss: 0.2730\n",
      "Epoch [114 /100], Loss: 0.2727\n",
      "Epoch [115 /100], Loss: 0.2725\n",
      "Epoch [116 /100], Loss: 0.2723\n",
      "Epoch [117 /100], Loss: 0.2721\n",
      "Epoch [118 /100], Loss: 0.2719\n",
      "Epoch [119 /100], Loss: 0.2716\n",
      "Epoch [120 /100], Loss: 0.2714\n",
      "Epoch [121 /100], Loss: 0.2712\n",
      "Epoch [122 /100], Loss: 0.2711\n",
      "Epoch [123 /100], Loss: 0.2709\n",
      "Epoch [124 /100], Loss: 0.2707\n",
      "Epoch [125 /100], Loss: 0.2705\n",
      "Epoch [126 /100], Loss: 0.2703\n",
      "Epoch [127 /100], Loss: 0.2702\n",
      "Epoch [128 /100], Loss: 0.2700\n",
      "Epoch [129 /100], Loss: 0.2698\n",
      "Epoch [130 /100], Loss: 0.2697\n",
      "Epoch [131 /100], Loss: 0.2695\n",
      "Epoch [132 /100], Loss: 0.2694\n",
      "Epoch [133 /100], Loss: 0.2692\n",
      "Epoch [134 /100], Loss: 0.2691\n",
      "Epoch [135 /100], Loss: 0.2689\n",
      "Epoch [136 /100], Loss: 0.2688\n",
      "Epoch [137 /100], Loss: 0.2687\n",
      "Epoch [138 /100], Loss: 0.2685\n",
      "Epoch [139 /100], Loss: 0.2684\n",
      "Epoch [140 /100], Loss: 0.2683\n",
      "Epoch [141 /100], Loss: 0.2681\n",
      "Epoch [142 /100], Loss: 0.2680\n",
      "Epoch [143 /100], Loss: 0.2679\n",
      "Epoch [144 /100], Loss: 0.2678\n",
      "Epoch [145 /100], Loss: 0.2677\n",
      "Epoch [146 /100], Loss: 0.2676\n",
      "Epoch [147 /100], Loss: 0.2674\n",
      "Epoch [148 /100], Loss: 0.2673\n",
      "Epoch [149 /100], Loss: 0.2672\n",
      "Epoch [150 /100], Loss: 0.2671\n",
      "Epoch [151 /100], Loss: 0.2670\n",
      "Epoch [152 /100], Loss: 0.2669\n",
      "Epoch [153 /100], Loss: 0.2668\n",
      "Epoch [154 /100], Loss: 0.2668\n",
      "Epoch [155 /100], Loss: 0.2667\n",
      "Epoch [156 /100], Loss: 0.2666\n",
      "Epoch [157 /100], Loss: 0.2665\n",
      "Epoch [158 /100], Loss: 0.2664\n",
      "Epoch [159 /100], Loss: 0.2663\n",
      "Epoch [160 /100], Loss: 0.2662\n",
      "Epoch [161 /100], Loss: 0.2661\n",
      "Epoch [162 /100], Loss: 0.2661\n",
      "Epoch [163 /100], Loss: 0.2660\n",
      "Epoch [164 /100], Loss: 0.2659\n",
      "Epoch [165 /100], Loss: 0.2658\n",
      "Epoch [166 /100], Loss: 0.2658\n",
      "Epoch [167 /100], Loss: 0.2657\n",
      "Epoch [168 /100], Loss: 0.2656\n",
      "Epoch [169 /100], Loss: 0.2656\n",
      "Epoch [170 /100], Loss: 0.2655\n",
      "Epoch [171 /100], Loss: 0.2654\n",
      "Epoch [172 /100], Loss: 0.2654\n",
      "Epoch [173 /100], Loss: 0.2653\n",
      "Epoch [174 /100], Loss: 0.2652\n",
      "Epoch [175 /100], Loss: 0.2652\n",
      "Epoch [176 /100], Loss: 0.2651\n",
      "Epoch [177 /100], Loss: 0.2651\n",
      "Epoch [178 /100], Loss: 0.2650\n",
      "Epoch [179 /100], Loss: 0.2649\n",
      "Epoch [180 /100], Loss: 0.2649\n",
      "Epoch [181 /100], Loss: 0.2648\n",
      "Epoch [182 /100], Loss: 0.2648\n",
      "Epoch [183 /100], Loss: 0.2647\n",
      "Epoch [184 /100], Loss: 0.2647\n",
      "Epoch [185 /100], Loss: 0.2646\n",
      "Epoch [186 /100], Loss: 0.2646\n",
      "Epoch [187 /100], Loss: 0.2645\n",
      "Epoch [188 /100], Loss: 0.2645\n",
      "Epoch [189 /100], Loss: 0.2644\n",
      "Epoch [190 /100], Loss: 0.2644\n",
      "Epoch [191 /100], Loss: 0.2643\n",
      "Epoch [192 /100], Loss: 0.2643\n",
      "Epoch [193 /100], Loss: 0.2643\n",
      "Epoch [194 /100], Loss: 0.2642\n",
      "Epoch [195 /100], Loss: 0.2642\n",
      "Epoch [196 /100], Loss: 0.2641\n",
      "Epoch [197 /100], Loss: 0.2641\n",
      "Epoch [198 /100], Loss: 0.2640\n",
      "Epoch [199 /100], Loss: 0.2640\n",
      "Epoch [200 /100], Loss: 0.2640\n",
      "Epoch [201 /100], Loss: 0.2639\n",
      "Epoch [202 /100], Loss: 0.2639\n",
      "Epoch [203 /100], Loss: 0.2639\n",
      "Epoch [204 /100], Loss: 0.2638\n",
      "Epoch [205 /100], Loss: 0.2638\n",
      "Epoch [206 /100], Loss: 0.2638\n",
      "Epoch [207 /100], Loss: 0.2637\n",
      "Epoch [208 /100], Loss: 0.2637\n",
      "Epoch [209 /100], Loss: 0.2637\n",
      "Epoch [210 /100], Loss: 0.2636\n",
      "Epoch [211 /100], Loss: 0.2636\n",
      "Epoch [212 /100], Loss: 0.2636\n",
      "Epoch [213 /100], Loss: 0.2635\n",
      "Epoch [214 /100], Loss: 0.2635\n",
      "Epoch [215 /100], Loss: 0.2635\n",
      "Epoch [216 /100], Loss: 0.2634\n",
      "Epoch [217 /100], Loss: 0.2634\n",
      "Epoch [218 /100], Loss: 0.2634\n",
      "Epoch [219 /100], Loss: 0.2634\n",
      "Epoch [220 /100], Loss: 0.2633\n",
      "Epoch [221 /100], Loss: 0.2633\n",
      "Epoch [222 /100], Loss: 0.2633\n",
      "Epoch [223 /100], Loss: 0.2632\n",
      "Epoch [224 /100], Loss: 0.2632\n",
      "Epoch [225 /100], Loss: 0.2632\n",
      "Epoch [226 /100], Loss: 0.2632\n",
      "Epoch [227 /100], Loss: 0.2631\n",
      "Epoch [228 /100], Loss: 0.2631\n",
      "Epoch [229 /100], Loss: 0.2631\n",
      "Epoch [230 /100], Loss: 0.2631\n",
      "Epoch [231 /100], Loss: 0.2631\n",
      "Epoch [232 /100], Loss: 0.2630\n",
      "Epoch [233 /100], Loss: 0.2630\n",
      "Epoch [234 /100], Loss: 0.2630\n",
      "Epoch [235 /100], Loss: 0.2630\n",
      "Epoch [236 /100], Loss: 0.2629\n",
      "Epoch [237 /100], Loss: 0.2629\n",
      "Epoch [238 /100], Loss: 0.2629\n",
      "Epoch [239 /100], Loss: 0.2629\n",
      "Epoch [240 /100], Loss: 0.2629\n",
      "Epoch [241 /100], Loss: 0.2628\n",
      "Epoch [242 /100], Loss: 0.2628\n",
      "Epoch [243 /100], Loss: 0.2628\n",
      "Epoch [244 /100], Loss: 0.2628\n",
      "Epoch [245 /100], Loss: 0.2628\n",
      "Epoch [246 /100], Loss: 0.2628\n",
      "Epoch [247 /100], Loss: 0.2627\n",
      "Epoch [248 /100], Loss: 0.2627\n",
      "Epoch [249 /100], Loss: 0.2627\n",
      "Epoch [250 /100], Loss: 0.2627\n",
      "Epoch [251 /100], Loss: 0.2627\n",
      "Epoch [252 /100], Loss: 0.2626\n",
      "Epoch [253 /100], Loss: 0.2626\n",
      "Epoch [254 /100], Loss: 0.2626\n",
      "Epoch [255 /100], Loss: 0.2626\n",
      "Epoch [256 /100], Loss: 0.2626\n",
      "Epoch [257 /100], Loss: 0.2626\n",
      "Epoch [258 /100], Loss: 0.2626\n",
      "Epoch [259 /100], Loss: 0.2625\n",
      "Epoch [260 /100], Loss: 0.2625\n",
      "Epoch [261 /100], Loss: 0.2625\n",
      "Epoch [262 /100], Loss: 0.2625\n",
      "Epoch [263 /100], Loss: 0.2625\n",
      "Epoch [264 /100], Loss: 0.2625\n",
      "Epoch [265 /100], Loss: 0.2625\n",
      "Epoch [266 /100], Loss: 0.2624\n",
      "Epoch [267 /100], Loss: 0.2624\n",
      "Epoch [268 /100], Loss: 0.2624\n",
      "Epoch [269 /100], Loss: 0.2624\n",
      "Epoch [270 /100], Loss: 0.2624\n",
      "Epoch [271 /100], Loss: 0.2624\n",
      "Epoch [272 /100], Loss: 0.2624\n",
      "Epoch [273 /100], Loss: 0.2624\n",
      "Epoch [274 /100], Loss: 0.2623\n",
      "Epoch [275 /100], Loss: 0.2623\n",
      "Epoch [276 /100], Loss: 0.2623\n",
      "Epoch [277 /100], Loss: 0.2623\n",
      "Epoch [278 /100], Loss: 0.2623\n",
      "Epoch [279 /100], Loss: 0.2623\n",
      "Epoch [280 /100], Loss: 0.2623\n",
      "Epoch [281 /100], Loss: 0.2623\n",
      "Epoch [282 /100], Loss: 0.2623\n",
      "Epoch [283 /100], Loss: 0.2622\n",
      "Epoch [284 /100], Loss: 0.2622\n",
      "Epoch [285 /100], Loss: 0.2622\n",
      "Epoch [286 /100], Loss: 0.2622\n",
      "Epoch [287 /100], Loss: 0.2622\n",
      "Epoch [288 /100], Loss: 0.2622\n",
      "Epoch [289 /100], Loss: 0.2622\n",
      "Epoch [290 /100], Loss: 0.2622\n",
      "Epoch [291 /100], Loss: 0.2622\n",
      "Epoch [292 /100], Loss: 0.2622\n",
      "Epoch [293 /100], Loss: 0.2621\n",
      "Epoch [294 /100], Loss: 0.2621\n",
      "Epoch [295 /100], Loss: 0.2621\n",
      "Epoch [296 /100], Loss: 0.2621\n",
      "Epoch [297 /100], Loss: 0.2621\n",
      "Epoch [298 /100], Loss: 0.2621\n",
      "Epoch [299 /100], Loss: 0.2621\n",
      "Epoch [300 /100], Loss: 0.2621\n",
      "Epoch [301 /100], Loss: 0.2621\n",
      "Epoch [302 /100], Loss: 0.2621\n",
      "Epoch [303 /100], Loss: 0.2621\n",
      "Epoch [304 /100], Loss: 0.2620\n",
      "Epoch [305 /100], Loss: 0.2620\n",
      "Epoch [306 /100], Loss: 0.2620\n",
      "Epoch [307 /100], Loss: 0.2620\n",
      "Epoch [308 /100], Loss: 0.2620\n",
      "Epoch [309 /100], Loss: 0.2620\n",
      "Epoch [310 /100], Loss: 0.2620\n",
      "Epoch [311 /100], Loss: 0.2620\n",
      "Epoch [312 /100], Loss: 0.2620\n",
      "Epoch [313 /100], Loss: 0.2620\n",
      "Epoch [314 /100], Loss: 0.2620\n",
      "Epoch [315 /100], Loss: 0.2620\n",
      "Epoch [316 /100], Loss: 0.2620\n",
      "Epoch [317 /100], Loss: 0.2619\n",
      "Epoch [318 /100], Loss: 0.2619\n",
      "Epoch [319 /100], Loss: 0.2619\n",
      "Epoch [320 /100], Loss: 0.2619\n",
      "Epoch [321 /100], Loss: 0.2619\n",
      "Epoch [322 /100], Loss: 0.2619\n",
      "Epoch [323 /100], Loss: 0.2619\n",
      "Epoch [324 /100], Loss: 0.2619\n",
      "Epoch [325 /100], Loss: 0.2619\n",
      "Epoch [326 /100], Loss: 0.2619\n",
      "Epoch [327 /100], Loss: 0.2619\n",
      "Epoch [328 /100], Loss: 0.2619\n",
      "Epoch [329 /100], Loss: 0.2619\n",
      "Epoch [330 /100], Loss: 0.2619\n",
      "Epoch [331 /100], Loss: 0.2619\n",
      "Epoch [332 /100], Loss: 0.2619\n",
      "Epoch [333 /100], Loss: 0.2618\n",
      "Epoch [334 /100], Loss: 0.2618\n",
      "Epoch [335 /100], Loss: 0.2618\n",
      "Epoch [336 /100], Loss: 0.2618\n",
      "Epoch [337 /100], Loss: 0.2618\n",
      "Epoch [338 /100], Loss: 0.2618\n",
      "Epoch [339 /100], Loss: 0.2618\n",
      "Epoch [340 /100], Loss: 0.2618\n",
      "Epoch [341 /100], Loss: 0.2618\n",
      "Epoch [342 /100], Loss: 0.2618\n",
      "Epoch [343 /100], Loss: 0.2618\n",
      "Epoch [344 /100], Loss: 0.2618\n",
      "Epoch [345 /100], Loss: 0.2618\n",
      "Epoch [346 /100], Loss: 0.2618\n",
      "Epoch [347 /100], Loss: 0.2618\n",
      "Epoch [348 /100], Loss: 0.2618\n",
      "Epoch [349 /100], Loss: 0.2618\n",
      "Epoch [350 /100], Loss: 0.2618\n",
      "Epoch [351 /100], Loss: 0.2618\n",
      "Epoch [352 /100], Loss: 0.2617\n",
      "Epoch [353 /100], Loss: 0.2617\n",
      "Epoch [354 /100], Loss: 0.2617\n",
      "Epoch [355 /100], Loss: 0.2617\n",
      "Epoch [356 /100], Loss: 0.2617\n",
      "Epoch [357 /100], Loss: 0.2617\n",
      "Epoch [358 /100], Loss: 0.2617\n",
      "Epoch [359 /100], Loss: 0.2617\n",
      "Epoch [360 /100], Loss: 0.2617\n",
      "Epoch [361 /100], Loss: 0.2617\n",
      "Epoch [362 /100], Loss: 0.2617\n",
      "Epoch [363 /100], Loss: 0.2617\n",
      "Epoch [364 /100], Loss: 0.2617\n",
      "Epoch [365 /100], Loss: 0.2617\n",
      "Epoch [366 /100], Loss: 0.2617\n",
      "Epoch [367 /100], Loss: 0.2617\n",
      "Epoch [368 /100], Loss: 0.2617\n",
      "Epoch [369 /100], Loss: 0.2617\n",
      "Epoch [370 /100], Loss: 0.2617\n",
      "Epoch [371 /100], Loss: 0.2617\n",
      "Epoch [372 /100], Loss: 0.2617\n",
      "Epoch [373 /100], Loss: 0.2617\n",
      "Epoch [374 /100], Loss: 0.2616\n",
      "Epoch [375 /100], Loss: 0.2616\n",
      "Epoch [376 /100], Loss: 0.2616\n",
      "Epoch [377 /100], Loss: 0.2616\n",
      "Epoch [378 /100], Loss: 0.2616\n",
      "Epoch [379 /100], Loss: 0.2616\n",
      "Epoch [380 /100], Loss: 0.2616\n",
      "Epoch [381 /100], Loss: 0.2616\n",
      "Epoch [382 /100], Loss: 0.2616\n",
      "Epoch [383 /100], Loss: 0.2616\n",
      "Epoch [384 /100], Loss: 0.2616\n",
      "Epoch [385 /100], Loss: 0.2616\n",
      "Epoch [386 /100], Loss: 0.2616\n",
      "Epoch [387 /100], Loss: 0.2616\n",
      "Epoch [388 /100], Loss: 0.2616\n",
      "Epoch [389 /100], Loss: 0.2616\n",
      "Epoch [390 /100], Loss: 0.2616\n",
      "Epoch [391 /100], Loss: 0.2616\n",
      "Epoch [392 /100], Loss: 0.2616\n",
      "Epoch [393 /100], Loss: 0.2616\n",
      "Epoch [394 /100], Loss: 0.2616\n",
      "Epoch [395 /100], Loss: 0.2616\n",
      "Epoch [396 /100], Loss: 0.2616\n",
      "Epoch [397 /100], Loss: 0.2616\n",
      "Epoch [398 /100], Loss: 0.2616\n",
      "Epoch [399 /100], Loss: 0.2616\n",
      "Epoch [400 /100], Loss: 0.2616\n",
      "Epoch [401 /100], Loss: 0.2616\n",
      "Epoch [402 /100], Loss: 0.2615\n",
      "Epoch [403 /100], Loss: 0.2615\n",
      "Epoch [404 /100], Loss: 0.2615\n",
      "Epoch [405 /100], Loss: 0.2615\n",
      "Epoch [406 /100], Loss: 0.2615\n",
      "Epoch [407 /100], Loss: 0.2615\n",
      "Epoch [408 /100], Loss: 0.2615\n",
      "Epoch [409 /100], Loss: 0.2615\n",
      "Epoch [410 /100], Loss: 0.2615\n",
      "Epoch [411 /100], Loss: 0.2615\n",
      "Epoch [412 /100], Loss: 0.2615\n",
      "Epoch [413 /100], Loss: 0.2615\n",
      "Epoch [414 /100], Loss: 0.2615\n",
      "Epoch [415 /100], Loss: 0.2615\n",
      "Epoch [416 /100], Loss: 0.2615\n",
      "Epoch [417 /100], Loss: 0.2615\n",
      "Epoch [418 /100], Loss: 0.2615\n",
      "Epoch [419 /100], Loss: 0.2615\n",
      "Epoch [420 /100], Loss: 0.2615\n",
      "Epoch [421 /100], Loss: 0.2615\n",
      "Epoch [422 /100], Loss: 0.2615\n",
      "Epoch [423 /100], Loss: 0.2615\n",
      "Epoch [424 /100], Loss: 0.2615\n",
      "Epoch [425 /100], Loss: 0.2615\n",
      "Epoch [426 /100], Loss: 0.2615\n",
      "Epoch [427 /100], Loss: 0.2615\n",
      "Epoch [428 /100], Loss: 0.2615\n",
      "Epoch [429 /100], Loss: 0.2615\n",
      "Epoch [430 /100], Loss: 0.2615\n",
      "Epoch [431 /100], Loss: 0.2615\n",
      "Epoch [432 /100], Loss: 0.2615\n",
      "Epoch [433 /100], Loss: 0.2615\n",
      "Epoch [434 /100], Loss: 0.2615\n",
      "Epoch [435 /100], Loss: 0.2615\n",
      "Epoch [436 /100], Loss: 0.2614\n",
      "Epoch [437 /100], Loss: 0.2614\n",
      "Epoch [438 /100], Loss: 0.2614\n",
      "Epoch [439 /100], Loss: 0.2614\n",
      "Epoch [440 /100], Loss: 0.2614\n",
      "Epoch [441 /100], Loss: 0.2614\n",
      "Epoch [442 /100], Loss: 0.2614\n",
      "Epoch [443 /100], Loss: 0.2614\n",
      "Epoch [444 /100], Loss: 0.2614\n",
      "Epoch [445 /100], Loss: 0.2614\n",
      "Epoch [446 /100], Loss: 0.2614\n",
      "Epoch [447 /100], Loss: 0.2614\n",
      "Epoch [448 /100], Loss: 0.2614\n",
      "Epoch [449 /100], Loss: 0.2614\n",
      "Epoch [450 /100], Loss: 0.2614\n",
      "Epoch [451 /100], Loss: 0.2614\n",
      "Epoch [452 /100], Loss: 0.2614\n",
      "Epoch [453 /100], Loss: 0.2614\n",
      "Epoch [454 /100], Loss: 0.2614\n",
      "Epoch [455 /100], Loss: 0.2614\n",
      "Epoch [456 /100], Loss: 0.2614\n",
      "Epoch [457 /100], Loss: 0.2614\n",
      "Epoch [458 /100], Loss: 0.2614\n",
      "Epoch [459 /100], Loss: 0.2614\n",
      "Epoch [460 /100], Loss: 0.2614\n",
      "Epoch [461 /100], Loss: 0.2614\n",
      "Epoch [462 /100], Loss: 0.2614\n",
      "Epoch [463 /100], Loss: 0.2614\n",
      "Epoch [464 /100], Loss: 0.2614\n",
      "Epoch [465 /100], Loss: 0.2614\n",
      "Epoch [466 /100], Loss: 0.2614\n",
      "Epoch [467 /100], Loss: 0.2614\n",
      "Epoch [468 /100], Loss: 0.2614\n",
      "Epoch [469 /100], Loss: 0.2614\n",
      "Epoch [470 /100], Loss: 0.2614\n",
      "Epoch [471 /100], Loss: 0.2614\n",
      "Epoch [472 /100], Loss: 0.2614\n",
      "Epoch [473 /100], Loss: 0.2614\n",
      "Epoch [474 /100], Loss: 0.2614\n",
      "Epoch [475 /100], Loss: 0.2614\n",
      "Epoch [476 /100], Loss: 0.2614\n",
      "Epoch [477 /100], Loss: 0.2614\n",
      "Epoch [478 /100], Loss: 0.2613\n",
      "Epoch [479 /100], Loss: 0.2613\n",
      "Epoch [480 /100], Loss: 0.2613\n",
      "Epoch [481 /100], Loss: 0.2613\n",
      "Epoch [482 /100], Loss: 0.2613\n",
      "Epoch [483 /100], Loss: 0.2613\n",
      "Epoch [484 /100], Loss: 0.2613\n",
      "Epoch [485 /100], Loss: 0.2613\n",
      "Epoch [486 /100], Loss: 0.2613\n",
      "Epoch [487 /100], Loss: 0.2613\n",
      "Epoch [488 /100], Loss: 0.2613\n",
      "Epoch [489 /100], Loss: 0.2613\n",
      "Epoch [490 /100], Loss: 0.2613\n",
      "Epoch [491 /100], Loss: 0.2613\n",
      "Epoch [492 /100], Loss: 0.2613\n",
      "Epoch [493 /100], Loss: 0.2613\n",
      "Epoch [494 /100], Loss: 0.2613\n",
      "Epoch [495 /100], Loss: 0.2613\n",
      "Epoch [496 /100], Loss: 0.2613\n",
      "Epoch [497 /100], Loss: 0.2613\n",
      "Epoch [498 /100], Loss: 0.2613\n",
      "Epoch [499 /100], Loss: 0.2613\n",
      "Epoch [500 /100], Loss: 0.2613\n",
      "Epoch [501 /100], Loss: 0.2613\n",
      "Epoch [502 /100], Loss: 0.2613\n",
      "Epoch [503 /100], Loss: 0.2613\n",
      "Epoch [504 /100], Loss: 0.2613\n",
      "Epoch [505 /100], Loss: 0.2613\n",
      "Epoch [506 /100], Loss: 0.2613\n",
      "Epoch [507 /100], Loss: 0.2613\n",
      "Epoch [508 /100], Loss: 0.2613\n",
      "Epoch [509 /100], Loss: 0.2613\n",
      "Epoch [510 /100], Loss: 0.2613\n",
      "Epoch [511 /100], Loss: 0.2613\n",
      "Epoch [512 /100], Loss: 0.2613\n",
      "Epoch [513 /100], Loss: 0.2613\n",
      "Epoch [514 /100], Loss: 0.2613\n",
      "Epoch [515 /100], Loss: 0.2613\n",
      "Epoch [516 /100], Loss: 0.2613\n",
      "Epoch [517 /100], Loss: 0.2613\n",
      "Epoch [518 /100], Loss: 0.2613\n",
      "Epoch [519 /100], Loss: 0.2613\n",
      "Epoch [520 /100], Loss: 0.2613\n",
      "Epoch [521 /100], Loss: 0.2613\n",
      "Epoch [522 /100], Loss: 0.2613\n",
      "Epoch [523 /100], Loss: 0.2613\n",
      "Epoch [524 /100], Loss: 0.2613\n",
      "Epoch [525 /100], Loss: 0.2613\n",
      "Epoch [526 /100], Loss: 0.2612\n",
      "Epoch [527 /100], Loss: 0.2612\n",
      "Epoch [528 /100], Loss: 0.2612\n",
      "Epoch [529 /100], Loss: 0.2612\n",
      "Epoch [530 /100], Loss: 0.2612\n",
      "Epoch [531 /100], Loss: 0.2612\n",
      "Epoch [532 /100], Loss: 0.2612\n",
      "Epoch [533 /100], Loss: 0.2612\n",
      "Epoch [534 /100], Loss: 0.2612\n",
      "Epoch [535 /100], Loss: 0.2612\n",
      "Epoch [536 /100], Loss: 0.2612\n",
      "Epoch [537 /100], Loss: 0.2612\n",
      "Epoch [538 /100], Loss: 0.2612\n",
      "Epoch [539 /100], Loss: 0.2612\n",
      "Epoch [540 /100], Loss: 0.2612\n",
      "Epoch [541 /100], Loss: 0.2612\n",
      "Epoch [542 /100], Loss: 0.2612\n",
      "Epoch [543 /100], Loss: 0.2612\n",
      "Epoch [544 /100], Loss: 0.2612\n",
      "Epoch [545 /100], Loss: 0.2612\n",
      "Epoch [546 /100], Loss: 0.2612\n",
      "Epoch [547 /100], Loss: 0.2612\n",
      "Epoch [548 /100], Loss: 0.2612\n",
      "Epoch [549 /100], Loss: 0.2612\n",
      "Epoch [550 /100], Loss: 0.2612\n",
      "Epoch [551 /100], Loss: 0.2612\n",
      "Epoch [552 /100], Loss: 0.2612\n",
      "Epoch [553 /100], Loss: 0.2612\n",
      "Epoch [554 /100], Loss: 0.2612\n",
      "Epoch [555 /100], Loss: 0.2612\n",
      "Epoch [556 /100], Loss: 0.2612\n",
      "Epoch [557 /100], Loss: 0.2612\n",
      "Epoch [558 /100], Loss: 0.2612\n",
      "Epoch [559 /100], Loss: 0.2612\n",
      "Epoch [560 /100], Loss: 0.2612\n",
      "Epoch [561 /100], Loss: 0.2612\n",
      "Epoch [562 /100], Loss: 0.2612\n",
      "Epoch [563 /100], Loss: 0.2612\n",
      "Epoch [564 /100], Loss: 0.2612\n",
      "Epoch [565 /100], Loss: 0.2612\n",
      "Epoch [566 /100], Loss: 0.2612\n",
      "Epoch [567 /100], Loss: 0.2612\n",
      "Epoch [568 /100], Loss: 0.2612\n",
      "Epoch [569 /100], Loss: 0.2612\n",
      "Epoch [570 /100], Loss: 0.2612\n",
      "Epoch [571 /100], Loss: 0.2612\n",
      "Epoch [572 /100], Loss: 0.2612\n",
      "Epoch [573 /100], Loss: 0.2612\n",
      "Epoch [574 /100], Loss: 0.2612\n",
      "Epoch [575 /100], Loss: 0.2612\n",
      "Epoch [576 /100], Loss: 0.2612\n",
      "Epoch [577 /100], Loss: 0.2612\n",
      "Epoch [578 /100], Loss: 0.2612\n",
      "Epoch [579 /100], Loss: 0.2611\n",
      "Epoch [580 /100], Loss: 0.2611\n",
      "Epoch [581 /100], Loss: 0.2611\n",
      "Epoch [582 /100], Loss: 0.2611\n",
      "Epoch [583 /100], Loss: 0.2611\n",
      "Epoch [584 /100], Loss: 0.2611\n",
      "Epoch [585 /100], Loss: 0.2611\n",
      "Epoch [586 /100], Loss: 0.2611\n",
      "Epoch [587 /100], Loss: 0.2611\n",
      "Epoch [588 /100], Loss: 0.2611\n",
      "Epoch [589 /100], Loss: 0.2611\n",
      "Epoch [590 /100], Loss: 0.2611\n",
      "Epoch [591 /100], Loss: 0.2611\n",
      "Epoch [592 /100], Loss: 0.2611\n",
      "Epoch [593 /100], Loss: 0.2611\n",
      "Epoch [594 /100], Loss: 0.2611\n",
      "Epoch [595 /100], Loss: 0.2611\n",
      "Epoch [596 /100], Loss: 0.2611\n",
      "Epoch [597 /100], Loss: 0.2611\n",
      "Epoch [598 /100], Loss: 0.2611\n",
      "Epoch [599 /100], Loss: 0.2611\n",
      "Epoch [600 /100], Loss: 0.2611\n",
      "Epoch [601 /100], Loss: 0.2611\n",
      "Epoch [602 /100], Loss: 0.2611\n",
      "Epoch [603 /100], Loss: 0.2611\n",
      "Epoch [604 /100], Loss: 0.2611\n",
      "Epoch [605 /100], Loss: 0.2611\n",
      "Epoch [606 /100], Loss: 0.2611\n",
      "Epoch [607 /100], Loss: 0.2611\n",
      "Epoch [608 /100], Loss: 0.2611\n",
      "Epoch [609 /100], Loss: 0.2611\n",
      "Epoch [610 /100], Loss: 0.2611\n",
      "Epoch [611 /100], Loss: 0.2611\n",
      "Epoch [612 /100], Loss: 0.2611\n",
      "Epoch [613 /100], Loss: 0.2611\n",
      "Epoch [614 /100], Loss: 0.2611\n",
      "Epoch [615 /100], Loss: 0.2611\n",
      "Epoch [616 /100], Loss: 0.2611\n",
      "Epoch [617 /100], Loss: 0.2611\n",
      "Epoch [618 /100], Loss: 0.2611\n",
      "Epoch [619 /100], Loss: 0.2611\n",
      "Epoch [620 /100], Loss: 0.2611\n",
      "Epoch [621 /100], Loss: 0.2611\n",
      "Epoch [622 /100], Loss: 0.2611\n",
      "Epoch [623 /100], Loss: 0.2611\n",
      "Epoch [624 /100], Loss: 0.2611\n",
      "Epoch [625 /100], Loss: 0.2611\n",
      "Epoch [626 /100], Loss: 0.2611\n",
      "Epoch [627 /100], Loss: 0.2611\n",
      "Epoch [628 /100], Loss: 0.2611\n",
      "Epoch [629 /100], Loss: 0.2611\n",
      "Epoch [630 /100], Loss: 0.2611\n",
      "Epoch [631 /100], Loss: 0.2611\n",
      "Epoch [632 /100], Loss: 0.2611\n",
      "Epoch [633 /100], Loss: 0.2611\n",
      "Epoch [634 /100], Loss: 0.2611\n",
      "Epoch [635 /100], Loss: 0.2611\n",
      "Epoch [636 /100], Loss: 0.2610\n",
      "Epoch [637 /100], Loss: 0.2610\n",
      "Epoch [638 /100], Loss: 0.2610\n",
      "Epoch [639 /100], Loss: 0.2610\n",
      "Epoch [640 /100], Loss: 0.2610\n",
      "Epoch [641 /100], Loss: 0.2610\n",
      "Epoch [642 /100], Loss: 0.2610\n",
      "Epoch [643 /100], Loss: 0.2610\n",
      "Epoch [644 /100], Loss: 0.2610\n",
      "Epoch [645 /100], Loss: 0.2610\n",
      "Epoch [646 /100], Loss: 0.2610\n",
      "Epoch [647 /100], Loss: 0.2610\n",
      "Epoch [648 /100], Loss: 0.2610\n",
      "Epoch [649 /100], Loss: 0.2610\n",
      "Epoch [650 /100], Loss: 0.2610\n",
      "Epoch [651 /100], Loss: 0.2610\n",
      "Epoch [652 /100], Loss: 0.2610\n",
      "Epoch [653 /100], Loss: 0.2610\n",
      "Epoch [654 /100], Loss: 0.2610\n",
      "Epoch [655 /100], Loss: 0.2610\n",
      "Epoch [656 /100], Loss: 0.2610\n",
      "Epoch [657 /100], Loss: 0.2610\n",
      "Epoch [658 /100], Loss: 0.2610\n",
      "Epoch [659 /100], Loss: 0.2610\n",
      "Epoch [660 /100], Loss: 0.2610\n",
      "Epoch [661 /100], Loss: 0.2610\n",
      "Epoch [662 /100], Loss: 0.2610\n",
      "Epoch [663 /100], Loss: 0.2610\n",
      "Epoch [664 /100], Loss: 0.2610\n",
      "Epoch [665 /100], Loss: 0.2610\n",
      "Epoch [666 /100], Loss: 0.2610\n",
      "Epoch [667 /100], Loss: 0.2610\n",
      "Epoch [668 /100], Loss: 0.2610\n",
      "Epoch [669 /100], Loss: 0.2610\n",
      "Epoch [670 /100], Loss: 0.2610\n",
      "Epoch [671 /100], Loss: 0.2610\n",
      "Epoch [672 /100], Loss: 0.2610\n",
      "Epoch [673 /100], Loss: 0.2610\n",
      "Epoch [674 /100], Loss: 0.2610\n",
      "Epoch [675 /100], Loss: 0.2610\n",
      "Epoch [676 /100], Loss: 0.2610\n",
      "Epoch [677 /100], Loss: 0.2610\n",
      "Epoch [678 /100], Loss: 0.2610\n",
      "Epoch [679 /100], Loss: 0.2610\n",
      "Epoch [680 /100], Loss: 0.2610\n",
      "Epoch [681 /100], Loss: 0.2610\n",
      "Epoch [682 /100], Loss: 0.2610\n",
      "Epoch [683 /100], Loss: 0.2610\n",
      "Epoch [684 /100], Loss: 0.2610\n",
      "Epoch [685 /100], Loss: 0.2610\n",
      "Epoch [686 /100], Loss: 0.2610\n",
      "Epoch [687 /100], Loss: 0.2610\n",
      "Epoch [688 /100], Loss: 0.2610\n",
      "Epoch [689 /100], Loss: 0.2610\n",
      "Epoch [690 /100], Loss: 0.2610\n",
      "Epoch [691 /100], Loss: 0.2610\n",
      "Epoch [692 /100], Loss: 0.2610\n",
      "Epoch [693 /100], Loss: 0.2610\n",
      "Epoch [694 /100], Loss: 0.2610\n",
      "Epoch [695 /100], Loss: 0.2609\n",
      "Epoch [696 /100], Loss: 0.2609\n",
      "Epoch [697 /100], Loss: 0.2609\n",
      "Epoch [698 /100], Loss: 0.2609\n",
      "Epoch [699 /100], Loss: 0.2609\n",
      "Epoch [700 /100], Loss: 0.2609\n",
      "Epoch [701 /100], Loss: 0.2609\n",
      "Epoch [702 /100], Loss: 0.2609\n",
      "Epoch [703 /100], Loss: 0.2609\n",
      "Epoch [704 /100], Loss: 0.2609\n",
      "Epoch [705 /100], Loss: 0.2609\n",
      "Epoch [706 /100], Loss: 0.2609\n",
      "Epoch [707 /100], Loss: 0.2609\n",
      "Epoch [708 /100], Loss: 0.2609\n",
      "Epoch [709 /100], Loss: 0.2609\n",
      "Epoch [710 /100], Loss: 0.2609\n",
      "Epoch [711 /100], Loss: 0.2609\n",
      "Epoch [712 /100], Loss: 0.2609\n",
      "Epoch [713 /100], Loss: 0.2609\n",
      "Epoch [714 /100], Loss: 0.2609\n",
      "Epoch [715 /100], Loss: 0.2609\n",
      "Epoch [716 /100], Loss: 0.2609\n",
      "Epoch [717 /100], Loss: 0.2609\n",
      "Epoch [718 /100], Loss: 0.2609\n",
      "Epoch [719 /100], Loss: 0.2609\n",
      "Epoch [720 /100], Loss: 0.2609\n",
      "Epoch [721 /100], Loss: 0.2609\n",
      "Epoch [722 /100], Loss: 0.2609\n",
      "Epoch [723 /100], Loss: 0.2609\n",
      "Epoch [724 /100], Loss: 0.2609\n",
      "Epoch [725 /100], Loss: 0.2609\n",
      "Epoch [726 /100], Loss: 0.2609\n",
      "Epoch [727 /100], Loss: 0.2609\n",
      "Epoch [728 /100], Loss: 0.2609\n",
      "Epoch [729 /100], Loss: 0.2609\n",
      "Epoch [730 /100], Loss: 0.2609\n",
      "Epoch [731 /100], Loss: 0.2609\n",
      "Epoch [732 /100], Loss: 0.2609\n",
      "Epoch [733 /100], Loss: 0.2609\n",
      "Epoch [734 /100], Loss: 0.2609\n",
      "Epoch [735 /100], Loss: 0.2609\n",
      "Epoch [736 /100], Loss: 0.2609\n",
      "Epoch [737 /100], Loss: 0.2609\n",
      "Epoch [738 /100], Loss: 0.2609\n",
      "Epoch [739 /100], Loss: 0.2609\n",
      "Epoch [740 /100], Loss: 0.2609\n",
      "Epoch [741 /100], Loss: 0.2609\n",
      "Epoch [742 /100], Loss: 0.2609\n",
      "Epoch [743 /100], Loss: 0.2609\n",
      "Epoch [744 /100], Loss: 0.2609\n",
      "Epoch [745 /100], Loss: 0.2609\n",
      "Epoch [746 /100], Loss: 0.2609\n",
      "Epoch [747 /100], Loss: 0.2609\n",
      "Epoch [748 /100], Loss: 0.2609\n",
      "Epoch [749 /100], Loss: 0.2609\n",
      "Epoch [750 /100], Loss: 0.2609\n",
      "Epoch [751 /100], Loss: 0.2609\n",
      "Epoch [752 /100], Loss: 0.2609\n",
      "Epoch [753 /100], Loss: 0.2609\n",
      "Epoch [754 /100], Loss: 0.2609\n",
      "Epoch [755 /100], Loss: 0.2609\n",
      "Epoch [756 /100], Loss: 0.2609\n",
      "Epoch [757 /100], Loss: 0.2608\n",
      "Epoch [758 /100], Loss: 0.2608\n",
      "Epoch [759 /100], Loss: 0.2608\n",
      "Epoch [760 /100], Loss: 0.2608\n",
      "Epoch [761 /100], Loss: 0.2608\n",
      "Epoch [762 /100], Loss: 0.2608\n",
      "Epoch [763 /100], Loss: 0.2608\n",
      "Epoch [764 /100], Loss: 0.2608\n",
      "Epoch [765 /100], Loss: 0.2608\n",
      "Epoch [766 /100], Loss: 0.2608\n",
      "Epoch [767 /100], Loss: 0.2608\n",
      "Epoch [768 /100], Loss: 0.2608\n",
      "Epoch [769 /100], Loss: 0.2608\n",
      "Epoch [770 /100], Loss: 0.2608\n",
      "Epoch [771 /100], Loss: 0.2608\n",
      "Epoch [772 /100], Loss: 0.2608\n",
      "Epoch [773 /100], Loss: 0.2608\n",
      "Epoch [774 /100], Loss: 0.2608\n",
      "Epoch [775 /100], Loss: 0.2608\n",
      "Epoch [776 /100], Loss: 0.2608\n",
      "Epoch [777 /100], Loss: 0.2608\n",
      "Epoch [778 /100], Loss: 0.2608\n",
      "Epoch [779 /100], Loss: 0.2608\n",
      "Epoch [780 /100], Loss: 0.2608\n",
      "Epoch [781 /100], Loss: 0.2608\n",
      "Epoch [782 /100], Loss: 0.2608\n",
      "Epoch [783 /100], Loss: 0.2608\n",
      "Epoch [784 /100], Loss: 0.2608\n",
      "Epoch [785 /100], Loss: 0.2608\n",
      "Epoch [786 /100], Loss: 0.2608\n",
      "Epoch [787 /100], Loss: 0.2608\n",
      "Epoch [788 /100], Loss: 0.2608\n",
      "Epoch [789 /100], Loss: 0.2608\n",
      "Epoch [790 /100], Loss: 0.2608\n",
      "Epoch [791 /100], Loss: 0.2608\n",
      "Epoch [792 /100], Loss: 0.2608\n",
      "Epoch [793 /100], Loss: 0.2608\n",
      "Epoch [794 /100], Loss: 0.2608\n",
      "Epoch [795 /100], Loss: 0.2608\n",
      "Epoch [796 /100], Loss: 0.2608\n",
      "Epoch [797 /100], Loss: 0.2608\n",
      "Epoch [798 /100], Loss: 0.2608\n",
      "Epoch [799 /100], Loss: 0.2608\n",
      "Epoch [800 /100], Loss: 0.2608\n",
      "Epoch [801 /100], Loss: 0.2608\n",
      "Epoch [802 /100], Loss: 0.2608\n",
      "Epoch [803 /100], Loss: 0.2608\n",
      "Epoch [804 /100], Loss: 0.2608\n",
      "Epoch [805 /100], Loss: 0.2608\n",
      "Epoch [806 /100], Loss: 0.2608\n",
      "Epoch [807 /100], Loss: 0.2608\n",
      "Epoch [808 /100], Loss: 0.2608\n",
      "Epoch [809 /100], Loss: 0.2608\n",
      "Epoch [810 /100], Loss: 0.2608\n",
      "Epoch [811 /100], Loss: 0.2608\n",
      "Epoch [812 /100], Loss: 0.2608\n",
      "Epoch [813 /100], Loss: 0.2608\n",
      "Epoch [814 /100], Loss: 0.2608\n",
      "Epoch [815 /100], Loss: 0.2608\n",
      "Epoch [816 /100], Loss: 0.2608\n",
      "Epoch [817 /100], Loss: 0.2608\n",
      "Epoch [818 /100], Loss: 0.2608\n",
      "Epoch [819 /100], Loss: 0.2607\n",
      "Epoch [820 /100], Loss: 0.2607\n",
      "Epoch [821 /100], Loss: 0.2607\n",
      "Epoch [822 /100], Loss: 0.2607\n",
      "Epoch [823 /100], Loss: 0.2607\n",
      "Epoch [824 /100], Loss: 0.2607\n",
      "Epoch [825 /100], Loss: 0.2607\n",
      "Epoch [826 /100], Loss: 0.2607\n",
      "Epoch [827 /100], Loss: 0.2607\n",
      "Epoch [828 /100], Loss: 0.2607\n",
      "Epoch [829 /100], Loss: 0.2607\n",
      "Epoch [830 /100], Loss: 0.2607\n",
      "Epoch [831 /100], Loss: 0.2607\n",
      "Epoch [832 /100], Loss: 0.2607\n",
      "Epoch [833 /100], Loss: 0.2607\n",
      "Epoch [834 /100], Loss: 0.2607\n",
      "Epoch [835 /100], Loss: 0.2607\n",
      "Epoch [836 /100], Loss: 0.2607\n",
      "Epoch [837 /100], Loss: 0.2607\n",
      "Epoch [838 /100], Loss: 0.2607\n",
      "Epoch [839 /100], Loss: 0.2607\n",
      "Epoch [840 /100], Loss: 0.2607\n",
      "Epoch [841 /100], Loss: 0.2607\n",
      "Epoch [842 /100], Loss: 0.2607\n",
      "Epoch [843 /100], Loss: 0.2607\n",
      "Epoch [844 /100], Loss: 0.2607\n",
      "Epoch [845 /100], Loss: 0.2607\n",
      "Epoch [846 /100], Loss: 0.2607\n",
      "Epoch [847 /100], Loss: 0.2607\n",
      "Epoch [848 /100], Loss: 0.2607\n",
      "Epoch [849 /100], Loss: 0.2607\n",
      "Epoch [850 /100], Loss: 0.2607\n",
      "Epoch [851 /100], Loss: 0.2607\n",
      "Epoch [852 /100], Loss: 0.2607\n",
      "Epoch [853 /100], Loss: 0.2607\n",
      "Epoch [854 /100], Loss: 0.2607\n",
      "Epoch [855 /100], Loss: 0.2607\n",
      "Epoch [856 /100], Loss: 0.2607\n",
      "Epoch [857 /100], Loss: 0.2607\n",
      "Epoch [858 /100], Loss: 0.2607\n",
      "Epoch [859 /100], Loss: 0.2607\n",
      "Epoch [860 /100], Loss: 0.2607\n",
      "Epoch [861 /100], Loss: 0.2607\n",
      "Epoch [862 /100], Loss: 0.2607\n",
      "Epoch [863 /100], Loss: 0.2607\n",
      "Epoch [864 /100], Loss: 0.2607\n",
      "Epoch [865 /100], Loss: 0.2607\n",
      "Epoch [866 /100], Loss: 0.2607\n",
      "Epoch [867 /100], Loss: 0.2607\n",
      "Epoch [868 /100], Loss: 0.2607\n",
      "Epoch [869 /100], Loss: 0.2607\n",
      "Epoch [870 /100], Loss: 0.2607\n",
      "Epoch [871 /100], Loss: 0.2607\n",
      "Epoch [872 /100], Loss: 0.2607\n",
      "Epoch [873 /100], Loss: 0.2607\n",
      "Epoch [874 /100], Loss: 0.2607\n",
      "Epoch [875 /100], Loss: 0.2607\n",
      "Epoch [876 /100], Loss: 0.2607\n",
      "Epoch [877 /100], Loss: 0.2607\n",
      "Epoch [878 /100], Loss: 0.2607\n",
      "Epoch [879 /100], Loss: 0.2607\n",
      "Epoch [880 /100], Loss: 0.2607\n",
      "Epoch [881 /100], Loss: 0.2607\n",
      "Epoch [882 /100], Loss: 0.2606\n",
      "Epoch [883 /100], Loss: 0.2606\n",
      "Epoch [884 /100], Loss: 0.2606\n",
      "Epoch [885 /100], Loss: 0.2606\n",
      "Epoch [886 /100], Loss: 0.2606\n",
      "Epoch [887 /100], Loss: 0.2606\n",
      "Epoch [888 /100], Loss: 0.2606\n",
      "Epoch [889 /100], Loss: 0.2606\n",
      "Epoch [890 /100], Loss: 0.2606\n",
      "Epoch [891 /100], Loss: 0.2606\n",
      "Epoch [892 /100], Loss: 0.2606\n",
      "Epoch [893 /100], Loss: 0.2606\n",
      "Epoch [894 /100], Loss: 0.2606\n",
      "Epoch [895 /100], Loss: 0.2606\n",
      "Epoch [896 /100], Loss: 0.2606\n",
      "Epoch [897 /100], Loss: 0.2606\n",
      "Epoch [898 /100], Loss: 0.2606\n",
      "Epoch [899 /100], Loss: 0.2606\n",
      "Epoch [900 /100], Loss: 0.2606\n",
      "Epoch [901 /100], Loss: 0.2606\n",
      "Epoch [902 /100], Loss: 0.2606\n",
      "Epoch [903 /100], Loss: 0.2606\n",
      "Epoch [904 /100], Loss: 0.2606\n",
      "Epoch [905 /100], Loss: 0.2606\n",
      "Epoch [906 /100], Loss: 0.2606\n",
      "Epoch [907 /100], Loss: 0.2606\n",
      "Epoch [908 /100], Loss: 0.2606\n",
      "Epoch [909 /100], Loss: 0.2606\n",
      "Epoch [910 /100], Loss: 0.2606\n",
      "Epoch [911 /100], Loss: 0.2606\n",
      "Epoch [912 /100], Loss: 0.2606\n",
      "Epoch [913 /100], Loss: 0.2606\n",
      "Epoch [914 /100], Loss: 0.2606\n",
      "Epoch [915 /100], Loss: 0.2606\n",
      "Epoch [916 /100], Loss: 0.2606\n",
      "Epoch [917 /100], Loss: 0.2606\n",
      "Epoch [918 /100], Loss: 0.2606\n",
      "Epoch [919 /100], Loss: 0.2606\n",
      "Epoch [920 /100], Loss: 0.2606\n",
      "Epoch [921 /100], Loss: 0.2606\n",
      "Epoch [922 /100], Loss: 0.2606\n",
      "Epoch [923 /100], Loss: 0.2606\n",
      "Epoch [924 /100], Loss: 0.2606\n",
      "Epoch [925 /100], Loss: 0.2606\n",
      "Epoch [926 /100], Loss: 0.2606\n",
      "Epoch [927 /100], Loss: 0.2606\n",
      "Epoch [928 /100], Loss: 0.2606\n",
      "Epoch [929 /100], Loss: 0.2606\n",
      "Epoch [930 /100], Loss: 0.2606\n",
      "Epoch [931 /100], Loss: 0.2606\n",
      "Epoch [932 /100], Loss: 0.2606\n",
      "Epoch [933 /100], Loss: 0.2606\n",
      "Epoch [934 /100], Loss: 0.2606\n",
      "Epoch [935 /100], Loss: 0.2606\n",
      "Epoch [936 /100], Loss: 0.2606\n",
      "Epoch [937 /100], Loss: 0.2606\n",
      "Epoch [938 /100], Loss: 0.2606\n",
      "Epoch [939 /100], Loss: 0.2606\n",
      "Epoch [940 /100], Loss: 0.2606\n",
      "Epoch [941 /100], Loss: 0.2606\n",
      "Epoch [942 /100], Loss: 0.2606\n",
      "Epoch [943 /100], Loss: 0.2606\n",
      "Epoch [944 /100], Loss: 0.2606\n",
      "Epoch [945 /100], Loss: 0.2606\n",
      "Epoch [946 /100], Loss: 0.2605\n",
      "Epoch [947 /100], Loss: 0.2605\n",
      "Epoch [948 /100], Loss: 0.2605\n",
      "Epoch [949 /100], Loss: 0.2605\n",
      "Epoch [950 /100], Loss: 0.2605\n",
      "Epoch [951 /100], Loss: 0.2605\n",
      "Epoch [952 /100], Loss: 0.2605\n",
      "Epoch [953 /100], Loss: 0.2605\n",
      "Epoch [954 /100], Loss: 0.2605\n",
      "Epoch [955 /100], Loss: 0.2605\n",
      "Epoch [956 /100], Loss: 0.2605\n",
      "Epoch [957 /100], Loss: 0.2605\n",
      "Epoch [958 /100], Loss: 0.2605\n",
      "Epoch [959 /100], Loss: 0.2605\n",
      "Epoch [960 /100], Loss: 0.2605\n",
      "Epoch [961 /100], Loss: 0.2605\n",
      "Epoch [962 /100], Loss: 0.2605\n",
      "Epoch [963 /100], Loss: 0.2605\n",
      "Epoch [964 /100], Loss: 0.2605\n",
      "Epoch [965 /100], Loss: 0.2605\n",
      "Epoch [966 /100], Loss: 0.2605\n",
      "Epoch [967 /100], Loss: 0.2605\n",
      "Epoch [968 /100], Loss: 0.2605\n",
      "Epoch [969 /100], Loss: 0.2605\n",
      "Epoch [970 /100], Loss: 0.2605\n",
      "Epoch [971 /100], Loss: 0.2605\n",
      "Epoch [972 /100], Loss: 0.2605\n",
      "Epoch [973 /100], Loss: 0.2605\n",
      "Epoch [974 /100], Loss: 0.2605\n",
      "Epoch [975 /100], Loss: 0.2605\n",
      "Epoch [976 /100], Loss: 0.2605\n",
      "Epoch [977 /100], Loss: 0.2605\n",
      "Epoch [978 /100], Loss: 0.2605\n",
      "Epoch [979 /100], Loss: 0.2605\n",
      "Epoch [980 /100], Loss: 0.2605\n",
      "Epoch [981 /100], Loss: 0.2605\n",
      "Epoch [982 /100], Loss: 0.2605\n",
      "Epoch [983 /100], Loss: 0.2605\n",
      "Epoch [984 /100], Loss: 0.2605\n",
      "Epoch [985 /100], Loss: 0.2605\n",
      "Epoch [986 /100], Loss: 0.2605\n",
      "Epoch [987 /100], Loss: 0.2605\n",
      "Epoch [988 /100], Loss: 0.2605\n",
      "Epoch [989 /100], Loss: 0.2605\n",
      "Epoch [990 /100], Loss: 0.2605\n",
      "Epoch [991 /100], Loss: 0.2605\n",
      "Epoch [992 /100], Loss: 0.2605\n",
      "Epoch [993 /100], Loss: 0.2605\n",
      "Epoch [994 /100], Loss: 0.2605\n",
      "Epoch [995 /100], Loss: 0.2605\n",
      "Epoch [996 /100], Loss: 0.2605\n",
      "Epoch [997 /100], Loss: 0.2605\n",
      "Epoch [998 /100], Loss: 0.2605\n",
      "Epoch [999 /100], Loss: 0.2605\n",
      "Epoch [1000 /100], Loss: 0.2605\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(feature_tensor)\n",
    "    loss = criterion(outputs, labels_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch [{epoch + 1} /100], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:16<00:00, 34.20s/it]\n"
     ]
    }
   ],
   "source": [
    "test_features = extract_image_features(test_loader, resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_tensor_test = torch.tensor(test_features, dtype=torch.float32).to(device)\n",
    "labels_tensor_test = torch.tensor(y_test_encoder, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_ouptputs = model(feature_tensor_test)\n",
    "    test_predictions = torch.sigmoid(test_ouptputs).cpu().numpy()\n",
    "    test_predictions = (test_predictions > 0.1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "       ambient       0.11      0.45      0.17        20\n",
      "          bass       0.00      0.00      0.00        12\n",
      "      chillout       0.00      0.00      0.00         6\n",
      "     classical       0.10      0.52      0.17        21\n",
      "         dance       0.00      0.00      0.00         8\n",
      "         drums       0.00      0.00      0.00        12\n",
      " easylistening       0.03      0.06      0.04        16\n",
      "electricguitar       0.00      0.00      0.00         6\n",
      "    electronic       0.13      1.00      0.22        25\n",
      "     emotional       0.00      0.00      0.00         6\n",
      "          film       0.00      0.00      0.00         8\n",
      "        guitar       0.00      0.00      0.00        15\n",
      "         happy       0.00      0.00      0.00        12\n",
      "        newage       0.00      0.00      0.00         8\n",
      "    orchestral       0.00      0.00      0.00         7\n",
      "         piano       0.13      1.00      0.22        25\n",
      "           pop       0.06      0.10      0.08        20\n",
      "      relaxing       0.00      0.00      0.00         7\n",
      "          rock       0.00      0.00      0.00        11\n",
      "    soundtrack       0.21      1.00      0.34        41\n",
      "   synthesizer       0.10      0.86      0.18        21\n",
      "\n",
      "     micro avg       0.13      0.43      0.19       307\n",
      "     macro avg       0.04      0.24      0.07       307\n",
      "  weighted avg       0.07      0.43      0.12       307\n",
      "   samples avg       0.13      0.44      0.19       307\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akovel/anaconda3/envs/diploma/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_encoder, test_predictions, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"multiclass_model_simple.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
